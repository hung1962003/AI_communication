from prompts import WELCOME_MESSAGE, conversation_prompt, feedback_prompt
import os
from dotenv import load_dotenv
from livekit import agents ,rtc
from livekit.agents import (
    Agent, AgentSession, JobContext, WorkerOptions,
    AutoSubscribe, RoomInputOptions
)
from livekit.agents.llm import ChatContext, ChatRole
from livekit.plugins import openai, deepgram, silero
from openai import OpenAI
import inspect
import asyncio
# ==== Load bi·∫øn m√¥i tr∆∞·ªùng ====
load_dotenv(".env")

# ==== Kh·ªüi t·∫°o client OpenAI ƒë·ªÉ ch·∫•m feedback ====
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ==== ƒê·ªãnh nghƒ©a Agent ====
class Assistant(Agent):
    def __init__(self) -> None:
        super().__init__(instructions=conversation_prompt)

# ==== H√†m ti·ªán √≠ch cho HTTP session (optional) ====
def _http_kwarg_for(klass, http):
    try:
        params = inspect.signature(klass.__init__).parameters
        if "http_session" in params:
            return {"http_session": http}
        if "session" in params:
            return {"session": http}
    except Exception:
        pass
    return {}

# ==== H√†m kh·ªüi t·∫°o ch√≠nh ====
async def entrypoint(ctx: agents.JobContext):
    # Kh·ªüi t·∫°o STT / TTS / LLM / VAD
    stt = deepgram.STT(model="nova-2")
    tts = openai.TTS(voice="alloy")
    vad = silero.VAD.load()

    # D√πng OpenAI plugin ƒë·ªÉ g·ªçi Groq API
    llm_kwargs = _http_kwarg_for(openai.LLM, None)
    llm = openai.LLM(
        model="gpt-4o-mini",
        api_key=os.getenv("OPENAI_API_KEY"),
        temperature=float(os.getenv("LLM_TEMPERATURE", "1.0"))
    )

    # Kh·ªüi t·∫°o agent ch√≠nh
    operator = Assistant()

    # T·∫°o phi√™n h·ªôi tho·∫°i (session)
    va = AgentSession(
        stt=stt,
        tts=tts,
        llm=llm,
        vad=vad,
        preemptive_generation=True
    )
    
    async def handle_session_start():
        try:
            print("üîπ Session started! B·∫Øt ƒë·∫ßu kh·ªüi t·∫°o context ho·∫∑c TTS ...")
            await asyncio.sleep(1)
            await va.generate_reply(instructions=WELCOME_MESSAGE)
            print("‚úÖ Ho√†n t·∫•t kh·ªüi t·∫°o!")
        except Exception as e:
            print("‚ö†Ô∏è L·ªói trong handle_session_start:", e)

    # G·ª≠i l·ªùi ch√†o ban ƒë·∫ßu
    @va.on("session_started")
    def on_session_started(_):
        asyncio.create_task(handle_session_start())
        
    # # --- conversation_item_added: sync wrapper + async handler ---
    # async def handle_user_message_async(ev):
    #     try:
    #         if ev.item.role != "user":
    #             return
    #         text = ev.item.text_content.strip()
    #         if not text:
    #             return

    #         # N·∫øu client.chat.completions.create l√† blocking, ch·∫°y trong thread
    #         def call_feedback():
    #             return client.chat.completions.create(
    #                 model="gpt-4o-mini",
    #                 messages=[
    #                     {"role": "system", "content": feedback_prompt},
    #                     {"role": "user", "content": text}
    #                 ]
    #             )

    #         # Ch·∫°y blocking call trong thread pool ƒë·ªÉ kh√¥ng block event loop
    #         fb_resp = await asyncio.to_thread(call_feedback)

    #         # Tr√≠ch n·ªôi dung feedback ‚Äî t√πy c·∫•u tr√∫c response c·ªßa client
    #         try:
    #             feedback = fb_resp.choices[0].message.content
    #         except Exception:
    #             # fallback: convert to str
    #             feedback = str(fb_resp)

    #         print(f"\nüìù Feedback for user:\n{feedback}\n")

    #         # (Tu·ª≥ b·∫°n mu·ªën) g·ª≠i feedback nh∆∞ m·ªôt reply TTS:
    #         # await va.generate_reply(instructions=feedback)  # ho·∫∑c tu·ª≥ logic
    #     except Exception as e:
    #         print("‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω user message:", e)
    # # S·ª± ki·ªán: khi c√≥ tin nh·∫Øn m·ªõi t·ª´ user
    # @va.on("conversation_item_added")
    # def on_user_message(ev):
    #      # wrapper sync ‚Äî t·∫°o task cho handler async
    #     asyncio.create_task(handle_user_message_async(ev))

    # B·∫Øt ƒë·∫ßu agent
    await va.start(
        room=ctx.room,
        agent=operator,
        room_input_options=RoomInputOptions(video_enabled=False, close_on_disconnect=True),
    )

    # K·∫øt n·ªëi v√†o ph√≤ng LiveKit
    await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)
    await va.generate_reply(instructions=WELCOME_MESSAGE)
    @ctx.room.on("disconnected")
    def on_disconnected(reason):
        print("Room ƒë√£ ng·∫Øt:", reason)
        asyncio.create_task(ctx.shutdown())

# ==== Ch·∫°y ·ª©ng d·ª•ng ch√≠nh ====
if __name__ == "__main__":
    agents.cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint))
